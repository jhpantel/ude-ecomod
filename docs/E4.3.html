<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Jelena H. Pantel" />


<title>Module 4.3 Exercise</title>

<script src="site_libs/header-attrs-2.21/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.0/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.0/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Ecological Modelling</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Syllabus
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="./schedule.html">Course schedule</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    About me
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="./aboutme.html">Learn more about me</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">Project 1</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./project1.html">Guidelines</a>
        </li>
        <li>
          <a href="./media/ugly_logistic_cheat_sheet.pdf">Example cheat sheet</a>
        </li>
        <li class="dropdown-submenu">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">Resources</a>
          <ul class="dropdown-menu" role="menu">
            <li>
              <a href="./stage.html">Stage structured models</a>
            </li>
            <li>
              <a href="./metapop.html">Metapopulation model</a>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li>
      <a href="./project2.pdf">Project 2</a>
    </li>
  </ul>
</li>
<li>
  <a href="./contact.html">Contact</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/githubusername/mywebsite">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Module 4.3 Exercise</h1>
<h4 class="author">Jelena H. Pantel</h4>
<h4 class="date">2023-12-13 15:43:46.180531</h4>

</div>


<div
id="exercise-1.-our-first-abc---estimating-parameters-of-gaussian-distribution-given-observed-data"
class="section level2">
<h2>Exercise 1. Our First ABC - estimating parameters of Gaussian
distribution given observed data</h2>
<div id="a.-normal-distribution" class="section level5">
<h5>A. Normal distribution</h5>
<p>You took some introductory statistics, so I hope you are familiar
with a Gaussian distribution (also referred to as a normal
distribution). It’s useful to try and attribute data to an underlying
probability distribution, so we can understand and make inference about
that data. For example, many traits that have a genetic basis follow a
normal distribution. Body length in animals is a good example of this.
Researchers in the early 1900s were quite interested in better
understanding genetic inheritance of traits of interest for animal
breeding, which is a key reason why population geneticists (RA Fisher)
were the ones who developed classical statistical tests such as Analysis
of Variance - the goal was to understand how evolution led to shifts in
normally distributed traits. The normal distribution itself was
discovered by Carl Friedrich Gauss (a German mathematician and
physicist!!) in 1809.</p>
<div class="float">
<img src="media/normal.png" style="width:40.0%"
alt="Human height. (a) Height distribution (inches) for 175 students in 1914 attending the Connecticut Agricultural College. (b) Graphical presentation of these student heights showing their close fit to a normal distribution. (a: Reprinted with permission from Albert and Blakeslee: Corn and Man. Journal of Heredity. 1914;5:51. Oxford University Press. b: Reprinted with permission from Brooker RJ: Genetics: Analysis &amp; Principles, 3rd ed. New York: McGrawHill, 2008.)" />
<div class="figcaption">Human height. (a) Height distribution (inches)
for 175 students in 1914 attending the Connecticut Agricultural College.
(b) Graphical presentation of these student heights showing their close
fit to a normal distribution. (a: Reprinted with permission from Albert
and Blakeslee: Corn and Man. Journal of Heredity. 1914;5:51. Oxford
University Press. b: Reprinted with permission from Brooker RJ:
Genetics: Analysis &amp; Principles, 3rd ed. New York: McGrawHill,
2008.)</div>
</div>
<p>We can plot data and use our own eyes to consider whether it follows
a normal distribution. But I would like you to have an awareness that
even claiming / stating “The data <span class="math inline">\(x\)</span>
follows a normal distribution” is - you guessed it - formulating a
model! So then, given a set of data, we can propose a model, and
estimate the paramater values when fitting that data to the model. We
will do this with a normal distribution today.</p>
</div>
<div
id="b.-the-easiest-typical-way-to-estimate-parameters-of-a-normal-model-when-fit-to-observed-data"
class="section level5">
<h5>B. The easiest / typical way to estimate parameters of a normal
model when fit to observed data</h5>
<p>The focus of today’s exercise will be to use Approximate Bayesian
Computation (ABC) for fitting data to models. ABC is most needed with
very complicated models where the underlying parameters are often unkown
and difficult to estimate. However, its best to show you how ABC works
by applying it to a simpler model. So we will learn to estimate the
parameters in a normal distribution given a set of data.</p>
<p>The dataset of interest is body weight of a common household insect.
Please run the following command to load the dataset:</p>
<pre class="r"><code># Dataset with measures of 1000 household insects body mass
# (g)
dat &lt;- read.csv(&quot;https://raw.githubusercontent.com/jhpantel/ude-ecomod/main/data/insect.csv&quot;,
    header = TRUE, row.names = 1)</code></pre>
<p>You can visualize and summarize the data - what is the mean
(<code>mean</code>) and standard deviation (<code>sd</code>) of the
dataset? What is the <em>natural logarithm</em> of the standard
deviation of the dataset (<code>log(sd)</code>)?</p>
<p>A normal distribution has two parameters to describe its shape - mean
(<span class="math inline">\(\mu\)</span>) and standard deviation (<span
class="math inline">\(\sigma\)</span>). The formula to generate a normal
curve is:</p>
<p><span class="math display">\[ p(x) = \frac{1}{\sigma \sqrt {2 \pi}}
e^{-\frac{1}{2}(\frac{x - \mu}{\sigma})^2}  \]</span> Where p(x) is the
probability of observing a value of <span
class="math inline">\(x\)</span> given the model. For example, if data
is drawn from a normal distribution centered on a mean (<span
class="math inline">\(\mu\)</span>) = 50 and standard deviation (<span
class="math inline">\(\sigma\)</span>) = 1, the normal distribution
looks like this:</p>
<pre class="r"><code>hist(rnorm(10000, 50, 1))</code></pre>
<p><img src="E4.3_files/figure-html/figures-1-1.png" width="50%" /></p>
<p>And the probability of observing a value of 60 given this model and
these parameters is quite low:</p>
<pre class="r"><code># This calculates p(60) using the formula given above
dnorm(60, 50, 1)</code></pre>
<pre><code>## [1] 7.694599e-23</code></pre>
<p>It is of interest to ‘fit your data to a normal model’. We can do
this very quickly in R - we provide our data <code>dat</code> to a
command <code>fitdist</code> in the R library <code>fitdistrplus</code>
- it fits your observed data to a normal model and returns estimates of
the model parameters (<span class="math inline">\(\mu\)</span> and <span
class="math inline">\(\sigma\)</span>):</p>
<pre class="r"><code>fitdistrplus::fitdist(data = dat$weight_g, distr = &quot;norm&quot;)</code></pre>
<pre><code>## Fitting of the distribution &#39; norm &#39; by maximum likelihood 
## Parameters:
##       estimate  Std. Error
## mean 3.4242893 0.004553051
## sd   0.1439801 0.003218794</code></pre>
<p>How does the <code>fitdist</code> model estimates for mean (<span
class="math inline">\(\mu\)</span>) and standard deviation (<span
class="math inline">\(\sigma\)</span>) compare to the true values used
to produce the data? Quite well.</p>
</div>
<div
id="c.-estimating-parameters-of-a-normal-model-using-abc-useful-when-you-have-more-complex-models"
class="section level5">
<h5>C. Estimating parameters of a normal model using ABC (useful when
you have more complex models)</h5>
<p>Let’s learn to use ABC (Approximate Bayesian Computation) to estimate
the most likely values of the model parameters given the observe data.
This is most useful when (1) you have a very complex model and (2) you
don’t know the underlying values of the parameters that produced the
observed data. ABC uses the following steps:</p>
<ul>
<li><p>data is simulated from an underlying model</p></li>
<li><p>summary statistics are calculated from each simulation</p></li>
<li><p>the values of these summary statistics are compared to observed
values</p></li>
<li><p>a ‘rejection algorithm’ is implemented, where simulations with
summary statistics that are very far from the observed values are
discarded</p></li>
<li><p>the remaining accepted simulations are used to calculate a
‘posterior distribution’ for underlying model parameters</p></li>
</ul>
<p>Let’s look at each step more closely:</p>
<p><strong>Step 1. Data is simulated from an underlying
model</strong></p>
<p>We stated previously we believe our data is drawn from a normal
distribution. We simulate 10000 datasets from a normal model, and we
randomly choose parameter values for each simultion from the normal
model. We can simulate draws from a normal distribution using the
command <code>rnorm</code>. Here is a quick example of how to simulate
drawing 1000 values from a normal distribution with mean 50, standard
deviation = 1:</p>
<pre class="r"><code># Randomly draw 1000 values from a normal distribution with
# mean 50, standard deviation 1
a &lt;- rnorm(1000, 50, 1)
hist(a)</code></pre>
<p><img src="E4.3_files/figure-html/figures-2-1.png" width="50%" /></p>
<p>We wish to repeat this process of simulating our insect data (1000
data points) 10,000 times. We do not know the underlying values of the
model parameters (<span class="math inline">\(\mu\)</span> and <span
class="math inline">\(\sigma\)</span>) that produced our data, so we run
our simulations with randomly chosen values for these. We establish a
realistic <strong>prior distribution</strong> for each parameter:</p>
<pre class="r"><code>mu_rand &lt;- runif(10000, -100, 100)  # What is this command doing?
sd_rand &lt;- runif(10000, 0, 20)</code></pre>
<p>Create a histogram (<code>hist</code>) for each of these - do they
look as you would expect?</p>
<p>Now for each set of parameters, we simulate data that’s meant to
mimic our observed insect data using a normal model. How can we do this?
Using the <code>rnorm</code> command - we simulate data under a random
normal model with parameters <span class="math inline">\(\mu\)</span>
and <span class="math inline">\(\sigma\)</span> from each of the 10,000
values we generated above. This works for a single parameter set like
this:</p>
<pre class="r"><code>b &lt;- rnorm(1000, mu_rand[1], sd_rand[1])
hist(b)</code></pre>
<p><img src="E4.3_files/figure-html/figures-3-1.png" width="50%" /></p>
<p>We can do this for all of the parameter sets this way:</p>
<pre class="r"><code>sim &lt;- array(NA, dim = c(10000, 1000))
for (i in 1:10000) {
    sim[i, ] &lt;- rnorm(1000, mu_rand[i], sd_rand[i])
}</code></pre>
<p>Every single dataset is different:</p>
<pre class="r"><code>d &lt;- sample.int(10000, 8)
par(mfrow = c(2, 4))
for (i in d) {
    hist(sim[i, ])
}</code></pre>
<p><img src="E4.3_files/figure-html/figures-4-1.png" width="100%" /></p>
<p><strong>Step 2. Summary statistics are calculated from each
simulation</strong></p>
<p>Our focal summary statistics are (1) the mean of the dataset and (2)
the standard deviation of the dataset. We save those to a new variable
called <code>stat.obs</code>:</p>
<pre class="r"><code>stat.obs &lt;- c(mean(dat$weight_g), sd(dat$weight_g))</code></pre>
<p>Our simulated summary statistics can be obtained by calculating the
mean and sd for each of the 10000 simulations:</p>
<pre class="r"><code>stat.sim &lt;- array(NA, dim = c(10000, 2), dimnames = list(NULL,
    c(&quot;mean&quot;, &quot;sd&quot;)))
for (i in 1:10000) {
    stat.sim[i, 1] &lt;- mean(sim[i, ])
    stat.sim[i, 2] &lt;- sd(sim[i, ])
}</code></pre>
<p><strong>Step 3. The values of these summary statistics are compared
to observed values (using either a rejection algorithm or a neural
network - we use a neural network)</strong></p>
<p>We do this step using the R package <code>abc</code>:</p>
<pre class="r"><code>par.sim &lt;- cbind(mu_rand, sd_rand)
rej &lt;- abc::abc(target = stat.obs, param = par.sim, sumstat = stat.sim,
    tol = 0.1, method = &quot;neuralnet&quot;)</code></pre>
<pre><code>## 12345678910
## 12345678910</code></pre>
<p><strong>Step 4. The remaining accepted simulations are used to
calculate a ‘posterior distribution’ for underlying model
parameters</strong></p>
<p>We can visualize this by plotting the values of the accepted
simulations (the ones that are closest to our observed summary
statistics):</p>
<pre class="r"><code>par(mfrow = c(1, 1))
hist(rej$adj.values[, 1], main = &quot;posterior distribution of mean&quot;)</code></pre>
<p><img src="E4.3_files/figure-html/figures-5-1.png" width="100%" /></p>
<pre class="r"><code>hist(log(rej$adj.values[, 2]), main = &quot;posterior distribution of standard deviation&quot;)</code></pre>
<p><img src="E4.3_files/figure-html/figures-5-2.png" width="100%" /></p>
<p>How well do these compare to the observed values in the original data
(<code>obs.stat</code>)?</p>
</div>
<div
id="d.-estimating-parameters-of-a-discrete-time-lotka-volterra-model-using-abc"
class="section level5">
<h5>D. Estimating parameters of a discrete-time Lotka Volterra model
using ABC</h5>
<p>Let’s repeat using ABC (Approximate Bayesian Computation) to estimate
the most likely values of the model parameters given the observe data.
We can take Gause’s <em>Paramecium</em> data and try to estimate the
underlying parameters from a discrete-time Lotka Volterra model.</p>
<p><strong>Step 1a. Gather your observed data</strong></p>
<pre class="r"><code># load competition data
data(&quot;gause_1934_science_f02_03&quot;)

# subset out data from species grown in mixture
mixturedat &lt;- gause_1934_science_f02_03[gause_1934_science_f02_03$Treatment ==
    &quot;Mixture&quot;, ]

# extract time and species data
time &lt;- mixturedat$Day
species &lt;- data.frame(mixturedat$Volume_Species1, mixturedat$Volume_Species2)
colnames(species) &lt;- c(&quot;P_caudatum&quot;, &quot;P_aurelia&quot;)</code></pre>
<p><strong>Step 1b. Arrange your observed data similar to stat.obs
above</strong> The variable with the observed data,
<code>species</code>, has dimensions 23, 2. You should arrange the
observed data as a vector of length 46. That means, please arrange the
data in <code>species</code> to be 1 vector of length 46. Save that to a
new variable called <code>stat.obs</code> Hint: you can try the
<code>reshape2::melt</code> command, or you can create your own new
variable as <code>stat.obs &lt;- c(species[,1],species[,2])</code></p>
<p>Make sure your variable is correct by running this command and
getting the same results:</p>
<pre class="r"><code>length(stat.obs)</code></pre>
<pre><code>## [1] 46</code></pre>
<p><strong>Step 2. Create simulation of data from an underlying
model</strong></p>
<p>Our next goal is to use a discrete-time Lotka-Volterra model that can
simulate data of the kind observed in Gause’s Paramecium. The model
should consider the processes - growth and competition - that are
important to produce the observed Paramecium time series.</p>
<p>We use the following model:</p>
<p><span class="math display">\[ N_{1,t+1} = \frac{N_{1,t}
\lambda_{1}}{1 + \alpha_{11} N_{1,t} + \alpha_{12} N_{2,t}}\]</span>
<span class="math display">\[ N_{2,t+1} = \frac{N_{2,t} \lambda_{2}}{1 +
\alpha_{22} N_{2,t} + \alpha_{21} N_{1,t}}\]</span> The parameters we
need to estimate are:</p>
<p><span class="math inline">\(\lambda_1, \lambda_2, \alpha_{11},
\alpha_{22}, \alpha_{12}, \alpha_{21}\)</span></p>
<p>Please create a simulation of this model. I show here a model for a
single species. Please modify that to also simulate growth in a second
species. For the missing parameters, you can start by using values of
<span class="math inline">\(\lambda_2 = 1.5\)</span>, <span
class="math inline">\(\alpha_{22} = 0.005\)</span>, <span
class="math inline">\(\alpha_{12} = 0.03\)</span>, <span
class="math inline">\(\alpha_{21} = 0.007\)</span>, <span
class="math inline">\(N_{2,0} = 3\)</span>. Change the name of the
function to <code>disc_lv</code>.</p>
<pre class="r"><code># Parameter values to use for simulation
lambda_1 &lt;- 1.7
alpha_11 &lt;- 0.01
N1_0 &lt;- 5
t &lt;- 23
# model function
disc_log &lt;- function(lambda_1, N1_0, alpha_11) {
    Nt1 &lt;- (N1_0 * lambda_1)/(1 + alpha_11 * N1_0)
    return(Nt1)
}
# Simulation of model for t time steps
N &lt;- rep(NA, t)
N[1] &lt;- N1_0
for (i in 2:t) {
    N[i] &lt;- disc_log(lambda_1, N1_0, alpha_11)
    N1_0 &lt;- N[i]
}
# Plot simulation: ggplot
dat &lt;- as.data.frame(N)
dat$time &lt;- as.numeric(rownames(dat))
ggplot2::ggplot(dat, ggplot2::aes(time, N)) + ggplot2::geom_point()</code></pre>
<p><img src="E4.3_files/figure-html/unnamed-chunk-12-1.png" width="50%" /></p>
<pre class="r"><code># Plot simulation: base R
plot(N, xlab = &quot;time&quot;, ylab = &quot;N&quot;, pch = 19, col = &quot;black&quot;)</code></pre>
<p><img src="E4.3_files/figure-html/unnamed-chunk-12-2.png" width="50%" /></p>
<p><strong>Step 3. Create random simulations of data, using prior
distributions for model parameters</strong></p>
<p>Do you recall an exercise where we looked at logistic growth across a
range of values for the growth rate <span
class="math inline">\(\lambda\)</span>? We used code that looks like
this (using <code>disc_log</code> from above):</p>
<pre class="r"><code># Simulation of model for t time steps
lambda_1_range &lt;- c(0.6, 0.8, 1.2, 1.6, 1.8, 2)
N.g &lt;- numeric()
N1_0 &lt;- 5
for (p in 1:length(lambda_1_range)) {
    N &lt;- rep(NA, t)
    N[1] &lt;- N1_0
    for (i in 2:t) {
        N[i] &lt;- disc_log(lambda_1_range[p], N1_0, alpha_11)
        N1_0 &lt;- N[i]
    }
    dat &lt;- as.data.frame(N)
    dat$time &lt;- as.numeric(rownames(dat))
    dat$lambda &lt;- rep(lambda_1_range[p], t)
    N.g &lt;- rbind(N.g, dat)
    N1_0 &lt;- 5
}
# Plot in ggplot
ggplot2::ggplot(N.g, ggplot2::aes(x = time, y = N, col = as.factor(lambda))) +
    ggplot2::geom_line()</code></pre>
<p><img src="E4.3_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>In this exercise, you will choose a <em>prior distribution</em> for
each of the model parameters to estimate, and you will use a random draw
from that prior distribution for each repetition of the simulation. This
is how we create the variables <code>par.sim</code> and
<code>stat.sim</code> needed to use ABC, to estimate the unknown
parameter values for Gause’s Paramecium. I demonstrate how this works
for a discrete-time logistic example, using data from Gause’s
Paramecium.</p>
<pre class="r"><code>## 1. Get observed data load competition data
data(&quot;gause_1934_science_f02_03&quot;)
# subset out data from species grown alone (not in mixtire)
alone_dat &lt;- gause_1934_science_f02_03[gause_1934_science_f02_03$Treatment ==
    &quot;Pc&quot;, ]
# extract time and species data
time &lt;- alone_dat$Day
species &lt;- data.frame(alone_dat$Volume_Species1)
colnames(species) &lt;- &quot;P_caudatum&quot;

## 2. Arrange observed data for ABC
stat.obs &lt;- species$P_caudatum

## 3. Create a *random* simulation of disc_log, with draws
## from prior distributions for all model parameters. Save
## the time series values and values for the parameters in
## variables par.sim and stat.sim for ABC.
rand_disc_log &lt;- function(N1_0 = N1_0, disc_log, t) {
    ## Choose random values of lambda_1 from a prior
    ## distribution
    lambda_1r &lt;- runif(1, min = 1.2, max = 3)  # Random uniform distribution between 0-3
    alpha_11r &lt;- runif(1, min = -0.5, max = 0.5)  # Random uniform distribution, bounded -0.5 - 0.5
    # biased towards low values
    N &lt;- rep(NA, t)
    N[1] &lt;- N1_0
    for (i in 2:t) {
        N[i] &lt;- disc_log(lambda_1r, N1_0 = N1_0, alpha_11r)
        N1_0 &lt;- N[i]
    }
    return(list(N = N, lambda_1r = lambda_1r, alpha_11r = alpha_11r))
}

## 4. Run this function 1000 times, and save all of the
## time series and the associated parameter values for
## later ABC
num_iter &lt;- 1e+06
num_par &lt;- 2  # to estimate: lambda_11 and alpha_11
par_name &lt;- c(&quot;lambda_11&quot;, &quot;alpha_11&quot;)
par.sim &lt;- array(NA, dim = c(num_iter, num_par), dimnames = list(NULL,
    par_name))  # to save values of parameters
stat.sim &lt;- array(NA, dim = c(num_iter, t))  # to save values of N over time
colnames(stat.sim) &lt;- paste(&quot;S&quot;, 1:t, sep = &quot;&quot;)
for (k in 1:num_iter) {
    N1_0 &lt;- species$P_caudatum[1]
    simul &lt;- rand_disc_log(N1_0, disc_log, t)
    par.sim[k, 1] &lt;- simul$lambda_1r
    par.sim[k, 2] &lt;- simul$alpha_11r
    stat.sim[k, ] &lt;- simul$N
}

## 5. Use ABC to estimate the parameter values in the
## discrete-time growth model
colnames(stat.sim) &lt;- paste(&quot;S&quot;, 1:23, sep = &quot;&quot;)
rej_log &lt;- abc::abc(target = stat.obs, param = par.sim, sumstat = stat.sim,
    tol = 0.001, method = &quot;neuralnet&quot;)</code></pre>
<pre><code>## 12345678910
## 12345678910</code></pre>
<pre class="r"><code>## 6. Visualize the posterior distributions of the model
## parameters
par(mfrow = c(1, 1))
hist(rej_log$adj.values[, 1], main = &quot;posterior distribution of lambda_11&quot;)</code></pre>
<p><img src="E4.3_files/figure-html/unnamed-chunk-15-1.png" width="50%" /></p>
<pre class="r"><code>hist(rej_log$adj.values[, 2], main = &quot;posterior distribution of alpha_11&quot;)</code></pre>
<p><img src="E4.3_files/figure-html/unnamed-chunk-15-2.png" width="50%" /></p>
<pre class="r"><code>## 7. Add a curve to the observed data that shows the
## ABC-predicted parameter values 7a. Simulate data with
## the average &#39;accepted&#39; parameter values
lambda_1 &lt;- mean(rej_log$unadj.values[, 1])
alpha_11 &lt;- mean(rej_log$unadj.values[, 2])
N1_0 &lt;- species$P_caudatum[1]
t &lt;- 23
# model function
disc_log &lt;- function(lambda_1, N1_0, alpha_11) {
    Nt1 &lt;- (N1_0 * lambda_1)/(1 + alpha_11 * N1_0)
    return(Nt1)
}
# Simulation of model for t time steps
N &lt;- rep(NA, t)
N[1] &lt;- N1_0
for (i in 2:t) {
    N[i] &lt;- disc_log(lambda_1, N1_0, alpha_11)
    N1_0 &lt;- N[i]
}
plot(species$P_caudatum, pch = 19, col = &quot;black&quot;)
lines(N, lwd = 2, col = &quot;lightgray&quot;)</code></pre>
<p><img src="E4.3_files/figure-html/unnamed-chunk-15-3.png" width="50%" /></p>
<p><strong>Question: In this example, what are the prior distributions
for the lambda and alpha parameters?</strong></p>
<p><strong>Question: How do the posterior parameter distributions differ
from the prior distributions? Create a plot to show this.</strong></p>
<p><strong>Question: How does the predicted values of P. caudatum N
using the posterior mean compare to the observed values?</strong></p>
<p><strong>Question: Can you implement a different prior distribution
for alpha, using rnorm(0,0.01) ?</strong></p>
<p>Your goal is to repeat this ABC procedure and estimate the most
likely values for the 2 Paramecium species from the dataset in Step 1a.
The code above is your ‘template’ but using only 1 species. Add in the
model and parameters for Species #2, and be sure to add in draws of
parameter values from the prior distributions for those new
parameters.</p>
<p>I give an example here of what the model-estimated and observed data
look like.</p>
<p><img src="E4.3_files/figure-html/unnamed-chunk-17-1.png" width="50%" /></p>
<p>If you are struggling to get a good fit of the model to the data, you
can try:</p>
<ul>
<li><p>Narrowing the range of the prior distributions</p></li>
<li><p>I used the following prior for my <span
class="math inline">\(\alpha\)</span> coefficients:</p></li>
</ul>
<pre class="r"><code>z &lt;- rbinom(1, 1, 0.5)
alpha &lt;- z * -rbeta(1, shape1 = 1, shape2 = 50) + (1 - z) * rbeta(1,
    shape1 = 1, shape2 = 50)</code></pre>
<p>Note this gives both negative and positive values drawn from a beta
distribution.</p>
<ul>
<li><p>You can try running more iterations of the simulation. I used
100000.</p></li>
<li><p>You can work with either the adjusted or unadjusted values from
the ABC. The unadjusted values arise from using a <strong>rejection
method</strong> to converge on parameter value estimates that best fit
the data. The adjusted values arise from a <strong>neural
network</strong> method. Sometimes one method works better than another.
You can index those values this way:</p></li>
</ul>
<pre class="r"><code>rej_log &lt;- abc::abc(target = stat.obs, param = par.sim, sumstat = stat.sim,
    tol = 0.001, method = &quot;neuralnet&quot;)
# Adjusted values - from the neural network method
rej_log$adj.values
# Unadjusted values - from the rejection method
rej_log$unadj.values</code></pre>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
